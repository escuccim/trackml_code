{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "\n",
    "from sklearn.cluster.dbscan_ import dbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_labels(params):\n",
    "    hits, dz, eps = params\n",
    "    a = hits['phi'].values\n",
    "    z = hits['z'].values\n",
    "    zr = hits['zr'].values\n",
    "    aa = a + np.sign(z) * dz * z\n",
    "\n",
    "    f0 = np.cos(aa)\n",
    "    f1 = np.sin(aa)\n",
    "    f2 = zr\n",
    "    X = StandardScaler().fit_transform(np.column_stack([f0, f1, f2]))\n",
    "\n",
    "    _, l = dbscan(X, eps=eps, min_samples=1, n_jobs=-1)\n",
    "    return l + 1\n",
    "\n",
    "def add_count(l):\n",
    "    unique, reverse, count = np.unique(l, return_counts=True, return_inverse=True)\n",
    "    c = count[reverse]\n",
    "    c[np.where(l == 0)] = 0\n",
    "    c[np.where(c > 20)] = 0\n",
    "    return (l, c)\n",
    "\n",
    "def do_dbscan_predict(hits, eps=0.0035):\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    hits['r'] = np.sqrt(hits['x'] ** 2 + hits['y'] ** 2)\n",
    "    hits['zr'] = hits['z'] / hits['r']\n",
    "    hits['phi'] = np.arctan2(hits['y'], hits['x'])\n",
    "\n",
    "    params = []\n",
    "    for i in range(0, 20):\n",
    "        dz = i * 0.00001\n",
    "        params.append((hits, dz, eps))\n",
    "        if i > 0:\n",
    "             params.append((hits, -dz, eps))\n",
    "\n",
    "    for i in range(20, 60):\n",
    "        dz = i * 0.00001\n",
    "        params.append((hits, dz, eps))\n",
    "        params.append((hits, -dz, eps))\n",
    "             \n",
    "    pool = Pool(processes=14)\n",
    "    labels_for_all_steps = pool.map(find_labels, params)\n",
    "    results = [add_count(l) for l in labels_for_all_steps]\n",
    "    pool.close()\n",
    "\n",
    "    labels, counts = results[0]\n",
    "    for i in range(1, len(results)):\n",
    "        l, c = results[i]\n",
    "        idx = np.where((c - counts > 0))[0]\n",
    "        labels[idx] = l[idx] + labels.max()\n",
    "        counts[idx] = c[idx]\n",
    "\n",
    "    print('time spent:', round(timeit.default_timer() - start_time))\n",
    "\n",
    "    return labels\n",
    "\n",
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission\n",
    "\n",
    "def run_dbscan(eps=0.0035):\n",
    "    data_dir = './data/train_1'\n",
    "\n",
    "    event_ids = ['000001000','000001010','000001200','000001100']\n",
    "    sum = 0\n",
    "    sum_score = 0\n",
    "    for i, event_id in enumerate(event_ids):\n",
    "        hits, cells, particles, truth = load_event(data_dir + '/event' + event_id)\n",
    "        labels = do_dbscan_predict(hits, eps=eps)\n",
    "        submission = create_one_event_submission(0, hits['hit_id'].values, labels)\n",
    "        score = score_event(truth, submission)\n",
    "        print('[%2d] score : %0.8f' % (i, score))\n",
    "        sum_score += score\n",
    "        sum += 1\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print(\"Mean:\", sum_score / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate score by known events\n",
      "time spent: 18\n",
      "[ 0] score : 0.41206948\n",
      "time spent: 16\n",
      "[ 1] score : 0.40140858\n",
      "time spent: 18\n",
      "[ 2] score : 0.42780646\n",
      "time spent: 17\n",
      "[ 3] score : 0.42559620\n",
      "--------------------------------------\n",
      "Mean: 0.4167201787127368\n"
     ]
    }
   ],
   "source": [
    "print('estimate score by known events')\n",
    "run_dbscan(eps=0.0045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_preds(path_to_test=\"./data/test\", eps=0.0047, start=0):\n",
    "    test_dataset_submissions = []\n",
    "    print('process test events')\n",
    "    for event_id, hits in load_dataset(path_to_test, parts=['hits']):\n",
    "        if event_id >= start:\n",
    "            print('Event ID: ', event_id)\n",
    "            labels = do_dbscan_predict(hits, eps=eps)\n",
    "            # Prepare submission for an event\n",
    "            one_submission = create_one_event_submission(event_id, hits['hit_id'].values, labels)\n",
    "            test_dataset_submissions.append(one_submission)\n",
    "\n",
    "            one_submission.to_csv('./%09d.helix_baseline.csv.gz'%event_id, index=False, compression='gzip')\n",
    "            test_dataset_submissions.append(one_submission)\n",
    "    \n",
    "    return test_dataset_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process test events\n",
      "Event ID:  0\n",
      "time spent: 18\n",
      "Event ID:  1\n",
      "time spent: 19\n",
      "Event ID:  2\n",
      "time spent: 16\n",
      "Event ID:  3\n",
      "time spent: 17\n",
      "Event ID:  4\n",
      "time spent: 19\n",
      "Event ID:  5\n",
      "time spent: 17\n",
      "Event ID:  6\n",
      "time spent: 17\n",
      "Event ID:  7\n",
      "time spent: 18\n",
      "Event ID:  8\n",
      "time spent: 19\n",
      "Event ID:  9\n",
      "time spent: 18\n",
      "Event ID:  10\n",
      "time spent: 18\n",
      "Event ID:  11\n",
      "time spent: 17\n",
      "Event ID:  12\n",
      "time spent: 16\n",
      "Event ID:  13\n",
      "time spent: 21\n",
      "Event ID:  14\n",
      "time spent: 16\n",
      "Event ID:  15\n",
      "time spent: 14\n",
      "Event ID:  16\n",
      "time spent: 15\n",
      "Event ID:  17\n",
      "time spent: 22\n",
      "Event ID:  18\n",
      "time spent: 15\n",
      "Event ID:  19\n",
      "time spent: 16\n",
      "Event ID:  20\n",
      "time spent: 12\n",
      "Event ID:  21\n",
      "time spent: 17\n",
      "Event ID:  22\n",
      "time spent: 19\n",
      "Event ID:  23\n",
      "time spent: 18\n",
      "Event ID:  24\n",
      "time spent: 19\n",
      "Event ID:  25\n",
      "time spent: 17\n",
      "Event ID:  26\n",
      "time spent: 15\n",
      "Event ID:  27\n",
      "time spent: 16\n",
      "Event ID:  28\n",
      "time spent: 17\n",
      "Event ID:  29\n",
      "time spent: 14\n",
      "Event ID:  30\n",
      "time spent: 18\n",
      "Event ID:  31\n",
      "time spent: 16\n",
      "Event ID:  32\n",
      "time spent: 13\n",
      "Event ID:  33\n",
      "time spent: 13\n",
      "Event ID:  34\n",
      "time spent: 20\n",
      "Event ID:  35\n",
      "time spent: 16\n",
      "Event ID:  36\n",
      "time spent: 18\n",
      "Event ID:  37\n",
      "time spent: 21\n",
      "Event ID:  38\n",
      "time spent: 17\n",
      "Event ID:  39\n",
      "time spent: 19\n",
      "Event ID:  40\n",
      "time spent: 19\n",
      "Event ID:  41\n",
      "time spent: 17\n",
      "Event ID:  42\n",
      "time spent: 18\n",
      "Event ID:  43\n",
      "time spent: 17\n",
      "Event ID:  44\n",
      "time spent: 23\n",
      "Event ID:  45\n",
      "time spent: 16\n",
      "Event ID:  46\n",
      "time spent: 15\n",
      "Event ID:  47\n",
      "time spent: 14\n",
      "Event ID:  48\n",
      "time spent: 16\n",
      "Event ID:  49\n",
      "time spent: 19\n",
      "Event ID:  50\n",
      "time spent: 19\n",
      "Event ID:  51\n",
      "time spent: 18\n",
      "Event ID:  52\n",
      "time spent: 18\n",
      "Event ID:  53\n",
      "time spent: 17\n",
      "Event ID:  54\n",
      "time spent: 19\n",
      "Event ID:  55\n",
      "time spent: 16\n",
      "Event ID:  56\n",
      "time spent: 18\n",
      "Event ID:  57\n",
      "time spent: 20\n",
      "Event ID:  58\n",
      "time spent: 19\n",
      "Event ID:  59\n",
      "time spent: 18\n",
      "Event ID:  60\n",
      "time spent: 16\n",
      "Event ID:  61\n",
      "time spent: 17\n",
      "Event ID:  62\n",
      "time spent: 18\n",
      "Event ID:  63\n",
      "time spent: 19\n",
      "Event ID:  64\n",
      "time spent: 18\n",
      "Event ID:  65\n",
      "time spent: 15\n",
      "Event ID:  66\n",
      "time spent: 17\n",
      "Event ID:  67\n",
      "time spent: 21\n",
      "Event ID:  68\n",
      "time spent: 17\n",
      "Event ID:  69\n",
      "time spent: 16\n",
      "Event ID:  70\n",
      "time spent: 16\n",
      "Event ID:  71\n",
      "time spent: 18\n",
      "Event ID:  72\n",
      "time spent: 17\n",
      "Event ID:  73\n",
      "time spent: 17\n",
      "Event ID:  74\n",
      "time spent: 18\n",
      "Event ID:  75\n",
      "time spent: 16\n",
      "Event ID:  76\n",
      "time spent: 16\n",
      "Event ID:  77\n",
      "time spent: 14\n",
      "Event ID:  78\n",
      "time spent: 18\n",
      "Event ID:  79\n",
      "time spent: 14\n",
      "Event ID:  80\n",
      "time spent: 21\n",
      "Event ID:  81\n",
      "time spent: 17\n",
      "Event ID:  82\n",
      "time spent: 17\n",
      "Event ID:  83\n",
      "time spent: 21\n",
      "Event ID:  84\n",
      "time spent: 15\n",
      "Event ID:  85\n",
      "time spent: 18\n",
      "Event ID:  86\n",
      "time spent: 19\n",
      "Event ID:  87\n",
      "time spent: 19\n",
      "Event ID:  88\n",
      "time spent: 19\n",
      "Event ID:  89\n",
      "time spent: 19\n",
      "Event ID:  90\n",
      "time spent: 18\n",
      "Event ID:  91\n",
      "time spent: 16\n",
      "Event ID:  92\n",
      "time spent: 16\n",
      "Event ID:  93\n",
      "time spent: 22\n",
      "Event ID:  94\n",
      "time spent: 15\n",
      "Event ID:  95\n",
      "time spent: 19\n",
      "Event ID:  96\n",
      "time spent: 16\n",
      "Event ID:  97\n",
      "time spent: 18\n",
      "Event ID:  98\n",
      "time spent: 18\n",
      "Event ID:  99\n",
      "time spent: 19\n",
      "Event ID:  100\n",
      "time spent: 22\n",
      "Event ID:  101\n",
      "time spent: 21\n",
      "Event ID:  102\n",
      "time spent: 18\n",
      "Event ID:  103\n",
      "time spent: 16\n",
      "Event ID:  104\n",
      "time spent: 19\n",
      "Event ID:  105\n",
      "time spent: 15\n",
      "Event ID:  106\n",
      "time spent: 18\n",
      "Event ID:  107\n",
      "time spent: 21\n",
      "Event ID:  108\n",
      "time spent: 18\n",
      "Event ID:  109\n",
      "time spent: 19\n",
      "Event ID:  110\n",
      "time spent: 18\n",
      "Event ID:  111\n",
      "time spent: 18\n",
      "Event ID:  112\n",
      "time spent: 17\n",
      "Event ID:  113\n",
      "time spent: 21\n",
      "Event ID:  114\n",
      "time spent: 15\n",
      "Event ID:  115\n",
      "time spent: 16\n",
      "Event ID:  116\n",
      "time spent: 19\n",
      "Event ID:  117\n",
      "time spent: 19\n",
      "Event ID:  118\n",
      "time spent: 17\n",
      "Event ID:  119\n",
      "time spent: 14\n",
      "Event ID:  120\n",
      "time spent: 17\n",
      "Event ID:  121\n",
      "time spent: 19\n",
      "Event ID:  122\n",
      "time spent: 14\n",
      "Event ID:  123\n",
      "time spent: 16\n",
      "Event ID:  124\n",
      "time spent: 17\n"
     ]
    }
   ],
   "source": [
    "submissions = generate_test_preds(start=0, eps=0.0046)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13741466\n"
     ]
    }
   ],
   "source": [
    "event_ids = [ i for i in range(0,125) ]\n",
    "submissions = []\n",
    "for i,event_id in enumerate(event_ids):\n",
    "    submission  = pd.read_csv('./%09d.helix_baseline.csv.gz'%event_id, compression='gzip')\n",
    "    submissions.append(submission)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.concat(submissions, axis=0)\n",
    "submission.to_csv('20180701_helix_baseline_e_46.csv.gz', index=False, compression='gzip')\n",
    "print(len(submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

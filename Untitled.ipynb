{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trackML(dfh,w1,w2,w3,Niter,epsilon=.00350):\n",
    "    dfh['s1'] =dfh.hit_id\n",
    "    dfh['N1'] =1\n",
    "    dfh['r'] = dfh['r'] = np.sqrt(dfh['x'].values**2+dfh['y'].values**2+dfh['z'].values**2)\n",
    "    dfh['rt'] = np.sqrt(dfh['x'].values**2+dfh['y'].values**2)\n",
    "    dfh['a0'] = np.arctan2(dfh['y'].values,dfh['x'].values)\n",
    "    dfh['z1'] = dfh['z'].values/dfh['rt'].values\n",
    "    dfh['z2'] = dfh['z']/dfh['r']\n",
    "    mm = 1\n",
    "    \n",
    "    for ii in range(Niter+1):\n",
    "        mm = mm*(-1)\n",
    "        dfh['a1'] = dfh['a0'].values+mm*(dfh['rt']+0.000005*dfh['rt']**2)/1000*(ii/2)/180*math.pi\n",
    "        dfh['z'].values*np.sign(dfh['z'].values)\n",
    "        dfh['sina1'] = np.sin(dfh['a1'].values)\n",
    "        dfh['cosa1'] = np.cos(dfh['a1'].values)\n",
    "        ss = StandardScaler()\n",
    "        dfs = ss.fit_transform(dfh[['sina1','cosa1','z1','x1','x2']].values)\n",
    "        cx = np.array([w1,w1,w2,w3])\n",
    "        dfs = np.multiply(dfs, cx)\n",
    "        \n",
    "        clusters=DBSCAN(eps=self.epsilon+ii*stepeps,min_samples=1,metric='euclidean',n_jobs=1).fit(dfs).labels_ \n",
    "\n",
    "        if ii==0:\n",
    "            dfh['s1'] = clusters\n",
    "            dfh['N1'] = dfh.groupby('s1')['s1'].transform('count')\n",
    "\n",
    "        # else update our hits conditionally, if it's a better fit\n",
    "        else:\n",
    "            # put our new clusters to another feature\n",
    "            dfh['s2'] = clusters\n",
    "\n",
    "            # get the count of those clusters\n",
    "            dfh['N2'] = dfh.groupby('s2')['s2'].transform('count')\n",
    "            maxs1 = dfh['s1'].max()\n",
    "\n",
    "            # if our new clusters are bigger, but less than 20, use the new ones instead\n",
    "            cond = np.where((dfh['N2'].values>dfh['N1'].values) & (dfh['N2'].values<20))\n",
    "            s1 = dfh['s1'].values\n",
    "            s1[cond] = dfh['s2'].values[cond]+maxs1\n",
    "\n",
    "            # write the new clusters back to our dataframe\n",
    "            dfh['s1'] = s1\n",
    "            dfh['s1'] = dfh['s1'].astype('int64')\n",
    "            dfh['N1'] = dfh.groupby('s1')['s1'].transform('count')\n",
    "\n",
    "    return(dfh['s1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
